{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b1ceb1-2a03-4ad4-a066-f0102d9c81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# initialize the RNG deterministically\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef46445c-d290-4645-b3e0-5ea8a050bb88",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "dataset_name = \"CIFAR10\"\n",
    "model_name = \"resnet50_vicreg_ce\"\n",
    "ood = \"5:6:7:8:9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5811b2b1-ed7a-486b-9348-9f29fb5f3b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:01<00:00, 26698.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 27632.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# initialize data attributes and loaders\n",
    "from config import load_config\n",
    "\n",
    "config = load_config(\n",
    "    dataset_name = dataset_name,\n",
    "    model_name = model_name,\n",
    "    ood = ood,\n",
    ")\n",
    "config.load_data()\n",
    "config.print_labels()\n",
    "dm = config.datamodule\n",
    "\n",
    "assert dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5493260-073c-4c7d-8bd0-c02877854666",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(\"fit\")\n",
    "dm.setup(\"test\")\n",
    "dm.setup(\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96bcfe7b-1ec3-49b1-852e-0eb2aa820f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5:6:7:8:9 ui1ztwwv\n"
     ]
    }
   ],
   "source": [
    "# model ids\n",
    "model_ids = {\n",
    "    \"\": \"ls4e7esy\",\n",
    "    \"5:6:7:8:9\": \"ui1ztwwv\",\n",
    "    \"0:1:2:3:4\": \"07ij32ho\",\n",
    "}\n",
    "ood_str = \":\".join(map(str, config.ood))\n",
    "model_id = model_ids[ood_str]\n",
    "print(ood_str, model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a324bb12-44e2-4464-94d0-70d9f1c3dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201a37b8-a569-4818-877d-8dd195c35d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-ui1ztwwv:best, 419.59MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:2.6\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Model.__init__() missing 1 required positional argument: 'opt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WandbLogger\n\u001b[1;32m      4\u001b[0m artifact_dir \u001b[38;5;241m=\u001b[39m WandbLogger\u001b[38;5;241m.\u001b[39mdownload_artifact(artifact\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myasith/robustml/model-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:best\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel.ckpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39meval();\n",
      "File \u001b[0;32m~/.conda/envs/qpm-amrb/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1561\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1482\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1488\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \n\u001b[1;32m   1560\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1561\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/.conda/envs/qpm-amrb/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:89\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m---> 89\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "File \u001b[0;32m~/.conda/envs/qpm-amrb/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:156\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cls_spec\u001b[38;5;241m.\u001b[39mvarkw:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     _cls_kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _cls_kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m cls_init_args_name}\n\u001b[0;32m--> 156\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_cls_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# give model a chance to load something\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     obj\u001b[38;5;241m.\u001b[39mon_load_checkpoint(checkpoint)\n",
      "\u001b[0;31mTypeError\u001b[0m: Model.__init__() missing 1 required positional argument: 'opt'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from lightning.pytorch.loggers.wandb import WandbLogger\n",
    "\n",
    "artifact_dir = WandbLogger.download_artifact(artifact=f\"yasith/robustml/model-{model_id}:best\")\n",
    "model = model.__class__.load_from_checkpoint(Path(artifact_dir) / \"model.ckpt\", config=config)\n",
    "model = model.cuda()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d03d9a-cb33-4ace-9e4a-e2d4b0dbe94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()\n",
    "test_loader = dm.test_dataloader()\n",
    "if ood_str:\n",
    "    predict_loader = dm.predict_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef2017e-b03e-4a5e-ab7a-08108ad0a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "trn_emb = []\n",
    "trn_rcn = []\n",
    "trn_lgt = []\n",
    "\n",
    "val_emb = []\n",
    "val_rcn = []\n",
    "val_lgt = []\n",
    "\n",
    "ind_emb = []\n",
    "ind_rcn = []\n",
    "ind_lgt = []\n",
    "ind_tgt = []\n",
    "\n",
    "if ood_str:\n",
    "    ood_emb = []\n",
    "    ood_rcn = []\n",
    "    ood_lgt = []\n",
    "    ood_tgt = []\n",
    "    \n",
    "rnd_emb = []\n",
    "rnd_rcn = []\n",
    "rnd_lgt = []\n",
    "\n",
    "# train set (ind)\n",
    "for batch_idx, batch in enumerate(tqdm(train_loader)):\n",
    "    x, y, *_ = batch\n",
    "    x = x.float().cuda()\n",
    "    emb, lgt, rcn = model(x)\n",
    "    trn_emb.extend(emb.detach().cpu().numpy())\n",
    "    trn_lgt.extend(lgt.detach().cpu().numpy())\n",
    "    trn_rcn.extend(rcn.detach().cpu().numpy())\n",
    "print(\"train - OK\")\n",
    "\n",
    "# val set (ind)\n",
    "for batch_idx, batch in enumerate(tqdm(val_loader)):\n",
    "    x, y, *_ = batch\n",
    "    x = x.float().cuda()\n",
    "    emb, lgt, rcn = model(x)\n",
    "    val_emb.extend(emb.detach().cpu().numpy())\n",
    "    val_lgt.extend(lgt.detach().cpu().numpy())\n",
    "    val_rcn.extend(rcn.detach().cpu().numpy())\n",
    "print(\"val - OK\")\n",
    "\n",
    "# test set (ind)\n",
    "for batch_idx, batch in enumerate(tqdm(test_loader)):\n",
    "    x, y, *_ = batch\n",
    "    x = x.float().cuda()\n",
    "    emb, lgt, rcn = model(x)\n",
    "    ind_emb.extend(emb.detach().cpu().numpy())\n",
    "    ind_lgt.extend(lgt.detach().cpu().numpy())\n",
    "    ind_rcn.extend(rcn.detach().cpu().numpy())\n",
    "    ind_tgt.extend(y.detach().cpu().numpy())\n",
    "print(\"test InD - OK\")\n",
    "\n",
    "# predict set (ood)\n",
    "if ood_str:\n",
    "    for batch_idx, batch in enumerate(tqdm(predict_loader)):\n",
    "        x, y, *_ = batch\n",
    "        x = x.float().cuda()\n",
    "        emb, lgt, rcn = model(x)\n",
    "        ood_emb.extend(emb.detach().cpu().numpy())\n",
    "        ood_lgt.extend(lgt.detach().cpu().numpy())\n",
    "        ood_rcn.extend(rcn.detach().cpu().numpy())\n",
    "        ood_tgt.extend(y.detach().cpu().numpy())\n",
    "    print(\"test OoD - OK\")\n",
    "\n",
    "# random set\n",
    "rnd_set = torch.randn(100, config.batch_size, *config.input_shape)\n",
    "for batch_idx, batch in enumerate(tqdm(rnd_set)):\n",
    "    x = batch\n",
    "    x = x.float().cuda()\n",
    "    emb, lgt, rcn = model(x)\n",
    "    rnd_emb.extend(emb.detach().cpu().numpy())\n",
    "    rnd_lgt.extend(lgt.detach().cpu().numpy())\n",
    "    rnd_rcn.extend(rcn.detach().cpu().numpy())\n",
    "print(\"test RnD - OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec766110-7e55-4d34-b8f9-6956b7f64865",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_emb = np.array(trn_emb).squeeze()\n",
    "trn_lgt = np.array(trn_lgt).squeeze()\n",
    "trn_rcn = np.array(trn_rcn)\n",
    "\n",
    "val_emb = np.array(val_emb).squeeze()\n",
    "val_lgt = np.array(val_lgt).squeeze()\n",
    "val_rcn = np.array(val_rcn)\n",
    "\n",
    "ind_emb = np.array(ind_emb).squeeze()\n",
    "ind_lgt = np.array(ind_lgt).squeeze()\n",
    "ind_rcn = np.array(ind_rcn)\n",
    "ind_tgt = np.array(ind_tgt)\n",
    "\n",
    "if ood_str:\n",
    "    ood_emb = np.array(ood_emb).squeeze()\n",
    "    ood_lgt = np.array(ood_lgt).squeeze()\n",
    "    ood_rcn = np.array(ood_rcn)\n",
    "    ood_tgt = np.array(ood_tgt)\n",
    "    \n",
    "rnd_emb = np.array(rnd_emb).squeeze()\n",
    "rnd_lgt = np.array(rnd_lgt).squeeze()\n",
    "rnd_rcn = np.array(rnd_rcn)\n",
    "\n",
    "print(trn_emb.shape, trn_lgt.shape, trn_rcn.shape)\n",
    "print(val_emb.shape, val_lgt.shape, val_rcn.shape)\n",
    "print(ind_emb.shape, ind_lgt.shape, ind_rcn.shape, ind_tgt.shape)\n",
    "if ood_str:\n",
    "    print(ood_emb.shape, ood_lgt.shape, ood_rcn.shape, ood_tgt.shape)\n",
    "print(rnd_emb.shape, rnd_lgt.shape, rnd_rcn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a11e0-6e0b-46a2-b38a-7659eabed606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsnecuda import TSNE\n",
    "\n",
    "n = ind_emb.shape[0]\n",
    "\n",
    "if ood_str:\n",
    "    all_emb = np.concatenate([ind_emb, ood_emb], axis=0)\n",
    "else:\n",
    "    all_emb = ind_emb\n",
    "\n",
    "emb2d = TSNE(n_components=2, perplexity=50, random_seed=42, learning_rate=10, n_iter=10000).fit_transform(all_emb)\n",
    "ind_emb2d = emb2d[:n]\n",
    "ood_emb2d = emb2d[n:]\n",
    "print(ind_emb2d.shape, ood_emb2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c841c4-abf3-437c-aa19-735bb79370db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "ind_labels = [config.labels[i] for i in ind_tgt]\n",
    "ood_labels = [config.labels[i] for i in ood_tgt]\n",
    "\n",
    "emb_data = pd.DataFrame()\n",
    "d1, d2 = ind_emb2d.T\n",
    "emb_data = pd.concat([emb_data, pd.DataFrame(dict(d1=d1, d2=d2, label=ind_labels, source=\"ind\"))])\n",
    "\n",
    "d1, d2 = ood_emb2d.T\n",
    "emb_data = pd.concat([emb_data, pd.DataFrame(dict(d1=d1, d2=d2, label=ood_labels, source=\"ood\"))])\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.suptitle(\"Latent Space\")\n",
    "sns.scatterplot(data=emb_data[(emb_data['source'] == \"ind\")], x=\"d1\", y=\"d2\", hue=\"label\", s=5, ax=ax1)\n",
    "ax1.set_title(\"InD Data\")\n",
    "sns.scatterplot(data=emb_data[(emb_data['source'] == \"ood\")], x=\"d1\", y=\"d2\", hue=\"label\", s=5, ax=ax2)\n",
    "ax2.set_title(\"OoD Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33299a-45a1-4e6d-90a6-8ff59f691e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index_emb = faiss.IndexFlatL2(ind_emb.shape[-1])\n",
    "index_emb.add(ind_emb)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
    "fig.suptitle(\"KNN distance to InD samples\")\n",
    "\n",
    "for j, k in enumerate(tqdm([5, 10, 20, 40])):\n",
    "    \n",
    "    Di, _ = index_emb.search(ind_emb, k)\n",
    "    Do, _ = index_emb.search(ood_emb, k)\n",
    "    Dr, _ = index_emb.search(rnd_emb, k)\n",
    "    ax = axs[j]\n",
    "    ax.set_title(f\"K={k}\")\n",
    "    sns.histplot(Di.mean(-1), fill=True, label='ind', stat='density', ax=ax)\n",
    "    sns.histplot(Do.mean(-1), fill=True, label='ood', stat='density', ax=ax)\n",
    "    # sns.histplot(Dr.mean(-1), fill=True, label='rnd', stat='density', ax=ax)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0823620-b0bd-4e3d-9af0-318bc87348da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index_emb = faiss.IndexFlatIP(ind_emb.shape[-1])\n",
    "index_emb.add(ind_emb)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
    "fig.suptitle(\"KNN distance to InD samples\")\n",
    "\n",
    "for j, k in enumerate(tqdm([5, 10, 20, 40])):\n",
    "    \n",
    "    Di, _ = index_emb.search(ind_emb, k)\n",
    "    Do, _ = index_emb.search(ood_emb, k)\n",
    "    Dr, _ = index_emb.search(rnd_emb, k)\n",
    "    ax = axs[j]\n",
    "    ax.set_title(f\"K={k}\")\n",
    "    sns.histplot(Di.mean(-1), fill=True, label='ind', stat='density', ax=ax)\n",
    "    sns.histplot(Do.mean(-1), fill=True, label='ood', stat='density', ax=ax)\n",
    "    # sns.histplot(Dr.mean(-1), fill=True, label='rnd', stat='density', ax=ax)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338233d-0ab7-4286-a2c9-c7f522615eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index_lgt = faiss.IndexFlatL2(ind_lgt.shape[-1])\n",
    "index_lgt.add(ind_lgt)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
    "fig.suptitle(\"KNN distance to InD samples\")\n",
    "\n",
    "for j, k in enumerate(tqdm([5, 10, 20, 40])):\n",
    "    \n",
    "    Di, _ = index_lgt.search(ind_lgt, k)\n",
    "    Do, _ = index_lgt.search(ood_lgt, k)\n",
    "    ax = axs[j]\n",
    "    ax.set_title(f\"K={k}\")\n",
    "    sns.histplot(Di.mean(-1), fill=True, label='ind', stat='density', ax=ax)\n",
    "    sns.histplot(Do.mean(-1), fill=True, label='ood', stat='density', ax=ax)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5ebcd-7432-45bd-a067-74ac4177223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index_lgt = faiss.IndexFlatIP(ind_lgt.shape[-1])\n",
    "index_lgt.add(ind_lgt)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
    "fig.suptitle(\"KNN distance to InD samples\")\n",
    "\n",
    "for j, k in enumerate(tqdm([5, 10, 20, 40])):\n",
    "    \n",
    "    Di, _ = index_lgt.search(ind_lgt, k)\n",
    "    Do, _ = index_lgt.search(ood_lgt, k)\n",
    "    ax = axs[j]\n",
    "    ax.set_title(f\"K={k}\")\n",
    "    sns.histplot(Di.mean(-1), fill=True, label='ind', stat='density', ax=ax)\n",
    "    sns.histplot(Do.mean(-1), fill=True, label='ood', stat='density', ax=ax)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02d295-02a6-44fc-89aa-cc5a011d4fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qpm-amrb)",
   "language": "python",
   "name": "qpm-amrb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
