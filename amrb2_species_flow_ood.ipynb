{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATASET_NAME=AMRB2_species\n",
      "env: MANIFOLD_D=512\n",
      "env: MODEL_NAME=flow_nll\n",
      "env: TRAIN_EPOCHS=50\n",
      "env: OOD_K=1\n"
     ]
    }
   ],
   "source": [
    "%env DATASET_NAME=AMRB2_species\n",
    "%env MANIFOLD_D=512\n",
    "%env MODEL_NAME=flow_nll\n",
    "%env TRAIN_EPOCHS=50\n",
    "%env OOD_K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn.metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import Config, load_config\n",
    "from datasets import init_dataloaders, init_labels, init_shape\n",
    "from models import get_model_optimizer_and_step\n",
    "from models.common import gen_topk_accs, load_model_state, save_model_state\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:LOG_LEVEL=INFO\n",
      "INFO:root:OOD_K=1\n",
      "INFO:root:DATA_DIR=/home/pjaya001/datasets\n",
      "INFO:root:DATASET_NAME=AMRB2_species\n",
      "INFO:root:MODEL_NAME=flow_nll\n",
      "INFO:root:EXPERIMENT_BASE=/home/pjaya001/experiments/ood_flows\n",
      "INFO:root:MANIFOLD_D=512\n",
      "INFO:root:BATCH_SIZE=32\n",
      "INFO:root:OPTIM_LR=0.001\n",
      "INFO:root:OPTIM_M=0.8\n",
      "INFO:root:TRAIN_EPOCHS=50\n",
      "INFO:root:EXC_RESUME=1\n",
      "INFO:root:Using device: cuda\n",
      "INFO:root:Dataset file: /home/pjaya001/datasets/AMRB2/ctr_1_fit_f32.imag.npz\n",
      "INFO:root:[preparation] loaded target info\n",
      "INFO:root:[preparation] performed train/test split\n",
      "INFO:root:Prepared datasets in 21.32330060005188 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing ind/ood split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Labels (train, test): ['Acinetobacter', 'E_coli', 'K_pneumoniae', 'S_aureus']\n",
      "INFO:root:Labels (ood): ['B_subtilis']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed ind/ood split\n",
      "315072 210048 14784\n"
     ]
    }
   ],
   "source": [
    "# initialize the RNG deterministically\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "# initialize data attributes and loaders\n",
    "init_labels(config)\n",
    "init_shape(config)\n",
    "init_dataloaders(config)\n",
    "\n",
    "config.print_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myasith\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pjaya001/projects/qpm-amrb-new/wandb/run-20230727_112510-xfludcp1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yasith/uq_ood/runs/xfludcp1' target=\"_blank\">AMRB2_species-M512-OOD1</a></strong> to <a href='https://wandb.ai/yasith/uq_ood' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yasith/uq_ood' target=\"_blank\">https://wandb.ai/yasith/uq_ood</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yasith/uq_ood/runs/xfludcp1' target=\"_blank\">https://wandb.ai/yasith/uq_ood/runs/xfludcp1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/yasith/uq_ood/runs/xfludcp1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f888b0f6f20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import wandb.plot\n",
    "\n",
    "wandb.init(\n",
    "    project=\"uq_ood\",\n",
    "    name=config.run_name,\n",
    "    config=config.run_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_stats_to_wandb(\n",
    "    stats: dict[str, dict],\n",
    "    config: Config,\n",
    "    step: int,\n",
    ") -> dict:\n",
    "    # initialize metric dict\n",
    "    metrics = {}\n",
    "    metrics[\"trn/loss\"] = None\n",
    "    metrics[\"trn/acc\"] = dict(acc1=None, acc2=None, acc3=None)\n",
    "    metrics[\"tid/loss\"] = None\n",
    "    metrics[\"tid/acc\"] = dict(acc1=None, acc2=None, acc3=None)\n",
    "    metrics[\"tod/loss\"] = None\n",
    "\n",
    "    # get label information\n",
    "    ind_labels, ood_labels = config.get_ind_labels(), config.get_ood_labels()\n",
    "    Ki, Ko = len(ind_labels), len(ood_labels)\n",
    "\n",
    "    figs = {}\n",
    "    if \"trn\" in stats:\n",
    "        metrics[\"trn/loss\"] = stats[\"trn\"][\"loss\"]\n",
    "        y_true_trn: np.ndarray = stats[\"trn\"][\"y_true\"]\n",
    "        y_prob_trn: np.ndarray = stats[\"trn\"][\"y_prob\"]\n",
    "        metrics[\"trn/acc\"] = gen_topk_accs(y_true_trn, y_prob_trn, Ki)\n",
    "\n",
    "        cm = sklearn.metrics.confusion_matrix(\n",
    "            y_true_trn, y_prob_trn.argmax(-1), labels=list(range(Ki))\n",
    "        )\n",
    "        disp = sklearn.metrics.ConfusionMatrixDisplay(cm, display_labels=ind_labels)\n",
    "        disp.plot()\n",
    "        fp = os.path.join(config.experiment_path, f\"cm_trn_e{step}.png\")\n",
    "        plt.savefig(fp)\n",
    "        figs[\"trn/cm\"] = wandb.Image(Image.open(fp))\n",
    "\n",
    "    y_true_tst = []\n",
    "    y_prob_tst = []\n",
    "\n",
    "    if \"tid\" in stats:\n",
    "        y_true_tid: np.ndarray = stats[\"tid\"][\"y_true\"]\n",
    "        y_prob_tid: np.ndarray = stats[\"tid\"][\"y_prob\"]\n",
    "        if len(y_true_tid) > 0:\n",
    "            metrics[\"tid/loss\"] = stats[\"tid\"][\"loss\"]\n",
    "            metrics[\"tid/acc\"] = gen_topk_accs(y_true_tid, y_prob_tid, Ki)\n",
    "            y_true_tst.append(y_true_tid)\n",
    "            y_prob_tst.append(y_prob_tid)\n",
    "\n",
    "    if \"tod\" in stats:\n",
    "        y_true_tod: np.ndarray = stats[\"tod\"][\"y_true\"]\n",
    "        y_prob_tod: np.ndarray = stats[\"tod\"][\"y_prob\"]\n",
    "        if len(y_true_tod) > 0:\n",
    "            metrics[\"tod/loss\"] = stats[\"tod\"][\"loss\"]\n",
    "            y_true_tst.append(y_true_tod)\n",
    "            y_prob_tst.append(y_prob_tod)\n",
    "\n",
    "    # concatenate y of tid and tod datasets\n",
    "    y_true_tst = np.concatenate(y_true_tst, axis=0)\n",
    "    y_prob_tst = np.concatenate(y_prob_tst, axis=0)\n",
    "\n",
    "    # zero-pad y_prob_tst for ood targets\n",
    "    y_prob_tst = np.pad(y_prob_tst, pad_width=((0, 0), (0, Ko)))\n",
    "    perm_labels = ind_labels + ood_labels\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(\n",
    "        y_true_tst, y_prob_tst.argmax(-1), labels=list(range(Ki + Ko))\n",
    "    )\n",
    "    disp = sklearn.metrics.ConfusionMatrixDisplay(cm, display_labels=perm_labels)\n",
    "    disp.plot()\n",
    "    fp = os.path.join(config.experiment_path, f\"cm_tst_e{step}.png\")\n",
    "    plt.savefig(fp)\n",
    "    plt.close()\n",
    "    figs[\"tst/cm\"] = wandb.Image(Image.open(fp))\n",
    "\n",
    "    tqdm.write(f\"Epoch {step}: {metrics}\")\n",
    "\n",
    "    join = lambda x: \",\".join(map(perm_labels.__getitem__, x))\n",
    "    fig_row_lbl = []\n",
    "    fig_a_data = []\n",
    "    fig_a_col_lbl = []\n",
    "    fig_b_data = []\n",
    "    fig_b_col_lbl = []\n",
    "\n",
    "    if \"trn\" in stats:\n",
    "        fig_row_lbl.append(\"trn\")\n",
    "        (E_x_trn, E_y_trn, E_xp_trn, E_yp_trn) = zip(*stats[\"trn\"][\"samples\"])\n",
    "        E_x_trn = np.concatenate(E_x_trn, axis=1)\n",
    "        E_xp_trn = np.concatenate(E_xp_trn, axis=1)\n",
    "        fig_a_data.append(E_x_trn)\n",
    "        fig_a_col_lbl.append(join(E_y_trn))\n",
    "        fig_b_data.append(E_xp_trn)\n",
    "        fig_b_col_lbl.append(join(E_yp_trn))\n",
    "\n",
    "    if \"tid\" in stats and len(stats[\"tid\"][\"y_true\"]) > 0:\n",
    "        fig_row_lbl.append(\"tid\")\n",
    "        (E_x_tid, E_y_tid, E_xp_tid, E_yp_tid) = zip(*stats[\"tid\"][\"samples\"])\n",
    "        E_x_tid = np.concatenate(E_x_tid, axis=1)\n",
    "        E_xp_tid = np.concatenate(E_xp_tid, axis=1)\n",
    "        fig_a_data.append(E_x_tid)\n",
    "        fig_a_col_lbl.append(join(E_y_tid))\n",
    "        fig_b_data.append(E_xp_tid)\n",
    "        fig_b_col_lbl.append(join(E_yp_tid))\n",
    "\n",
    "    if \"tod\" in stats and len(stats[\"tod\"][\"y_true\"]) > 0:\n",
    "        fig_row_lbl.append(\"tod\")\n",
    "        (E_x_tod, E_y_tod, E_xp_tod, E_yp_tod) = zip(*stats[\"tod\"][\"samples\"])\n",
    "        E_x_tod = np.concatenate(E_x_tod, axis=1)\n",
    "        E_xp_tod = np.concatenate(E_xp_tod, axis=1)\n",
    "        fig_a_data.append(E_x_tod)\n",
    "        fig_a_col_lbl.append(join(E_y_tod))\n",
    "        fig_b_data.append(E_xp_tod)\n",
    "        fig_b_col_lbl.append(join(E_yp_tod))\n",
    "\n",
    "    fig_a_data = np.concatenate(fig_a_data, axis=0)\n",
    "    fig_b_data = np.concatenate(fig_b_data, axis=0)\n",
    "\n",
    "    fig_row_lbl = \", \".join([f\"R{i+1}={v}\" for i, v in enumerate(fig_row_lbl)])\n",
    "    fig_a_col_lbl = \", \".join([f\"R{i+1}={v}\" for i, v in enumerate(fig_a_col_lbl)])\n",
    "    fig_b_col_lbl = \", \".join([f\"R{i+1}={v}\" for i, v in enumerate(fig_b_col_lbl)])\n",
    "    fig_a_cap = f\"sample inputs - rows: [{fig_row_lbl}] - targets: [{fig_a_col_lbl}]\"\n",
    "    fig_b_cap = f\"sample output - rows: [{fig_row_lbl}] - targets: [{fig_b_col_lbl}]\"\n",
    "\n",
    "    figs[\"samples/input\"] = wandb.Image(fig_a_data, caption=fig_a_cap)\n",
    "    figs[\"samples/output\"] = wandb.Image(fig_b_data, caption=fig_b_cap)\n",
    "\n",
    "    done_keys = [\"y_true\", \"y_prob\", \"y_ucty\", \"samples\"]\n",
    "\n",
    "    for prefix in [\"trn\", \"tid\", \"tod\"]:\n",
    "        if prefix not in stats:\n",
    "            continue\n",
    "        prefix_stats: dict = stats[prefix]\n",
    "        for key in set(prefix_stats).difference(done_keys):\n",
    "            val = prefix_stats[key]\n",
    "            # unbounded histograms\n",
    "            if key in [\"u_norm\", \"v_norm\", \"z_norm\", \"z_nll\"]:\n",
    "                val = np.tanh(val)\n",
    "                # save v_norm for AUROC computation\n",
    "                if key in [\"v_norm\"]:\n",
    "                    figs[f\"{prefix}/{key}\"] = val\n",
    "                counts, bins = np.histogram(val, bins=100, range=(0.0, 1.0))\n",
    "                plt.stairs(counts, bins)\n",
    "                fp = os.path.join(config.experiment_path, f\"{key}_{prefix}_e{step}.png\")\n",
    "                plt.savefig(fp)\n",
    "                figs[f\"{prefix}/{key}_hist\"] = wandb.Image(Image.open(fp))\n",
    "            # bounded histograms\n",
    "            elif key == \"y_ucty\":\n",
    "                counts, bins = np.histogram(val, bins=100, range=(0.0, 1.0))\n",
    "                plt.stairs(counts, bins)\n",
    "                fp = os.path.join(config.experiment_path, f\"{key}_{prefix}_e{step}.png\")\n",
    "                plt.savefig(fp)\n",
    "                figs[f\"{prefix}/{key}_hist\"] = wandb.Image(Image.open(fp))\n",
    "            # log everything else\n",
    "            else:\n",
    "                figs[f\"{prefix}/{key}\"] = val\n",
    "\n",
    "    prefix = \"ood_detection\"\n",
    "    if \"v_norm\" in stats[\"tid\"] and \"v_norm\" in stats[\"tod\"]:\n",
    "        tid_v_norm = stats[\"tid\"][\"v_norm\"]\n",
    "        tod_v_norm = stats[\"tod\"][\"v_norm\"]\n",
    "        B_InD = tid_v_norm.shape[0]\n",
    "        B_OoD = tod_v_norm.shape[0]\n",
    "        # binary classification labels for ID and OOD\n",
    "        values = np.concatenate([tid_v_norm, tod_v_norm], axis=0)\n",
    "        target = np.concatenate([np.zeros(B_InD), np.ones(B_OoD)], axis=0)\n",
    "        # ROC curve\n",
    "        disp = sklearn.metrics.RocCurveDisplay.from_predictions(target, values)\n",
    "        disp.plot()\n",
    "        fp = os.path.join(config.experiment_path, f\"roc_{prefix}_e{step}.png\")\n",
    "        plt.savefig(fp)\n",
    "        figs[f\"{prefix}/roc\"] = wandb.Image(Image.open(fp))\n",
    "        # PR curve\n",
    "        disp = sklearn.metrics.PrecisionRecallDisplay.from_predictions(target, values)\n",
    "        disp.plot()\n",
    "        fp = os.path.join(config.experiment_path, f\"prc_{prefix}_e{step}.png\")\n",
    "        plt.savefig(fp)\n",
    "        figs[f\"{prefix}/prc\"] = wandb.Image(Image.open(fp))\n",
    "        # AUROC\n",
    "        figs[f\"{prefix}/auroc\"] = sklearn.metrics.roc_auc_score(target, values)\n",
    "\n",
    "    data = {}\n",
    "    data.update(metrics)\n",
    "    data.update(figs)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:no saved model state: /home/pjaya001/experiments/ood_flows/AMRB2_species-M512-OOD1/flow_nll_model.pth\n",
      "INFO:root:Started Train/Test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch 1:  65%|██████▍   | 6394/9846, Loss(agg)=0.7274, Loss(y)=0.5152, Loss(x)=0.1881, Loss(v)=21.5261, Loss(z)=0.0025      "
     ]
    }
   ],
   "source": [
    "assert config.train_loader\n",
    "assert config.test_loader\n",
    "\n",
    "model, optim, step = get_model_optimizer_and_step(config)\n",
    "\n",
    "# load saved model and optimizer, if present\n",
    "load_model_state(model, config)\n",
    "model = model.float().to(config.device)\n",
    "\n",
    "wandb.watch(model, log_freq=100)\n",
    "\n",
    "# run train / test loops\n",
    "logging.info(\"Started Train/Test\")\n",
    "\n",
    "artifact = wandb.Artifact(f\"{config.run_name}-{config.model_name}\", type=\"model\")\n",
    "\n",
    "# loop over epochs\n",
    "for epoch in range(1, config.train_epochs + 1):\n",
    "    epoch_stats: dict = {}\n",
    "\n",
    "    # train\n",
    "    trn_stats = step(\n",
    "        prefix=\"train\",\n",
    "        model=model,\n",
    "        epoch=epoch,\n",
    "        config=config,\n",
    "        optim=optim,\n",
    "    )\n",
    "    epoch_stats[\"trn\"] = trn_stats\n",
    "\n",
    "    # test (InD)\n",
    "    tid_stats = step(\n",
    "        prefix=\"test_ind\",\n",
    "        model=model,\n",
    "        epoch=epoch,\n",
    "        config=config,\n",
    "    )\n",
    "    epoch_stats[\"tid\"] = tid_stats\n",
    "\n",
    "    # test (OoD)\n",
    "    tod_stats = step(\n",
    "        prefix=\"test_ood\",\n",
    "        model=model,\n",
    "        epoch=epoch,\n",
    "        config=config,\n",
    "    )\n",
    "    epoch_stats[\"tod\"] = tod_stats\n",
    "\n",
    "    wandb.log(epoch_stats_to_wandb(epoch_stats, config, epoch), step=epoch)\n",
    "\n",
    "    # save model and optimizer states\n",
    "    save_model_state(model, config, epoch)\n",
    "    fp = config.experiment_path\n",
    "    model_name = config.model_name\n",
    "    artifact.add_file(os.path.join(fp, f\"{model_name}_model_e{epoch}.pth\"))\n",
    "\n",
    "artifact.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
